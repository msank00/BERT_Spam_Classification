{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_Spam_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1mRPiLCeTup"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "A wide range of transformer-based models started coming up for different NLP tasks. There are multiple advantages of using transformer-based models, but the most important ones are:\n",
        "\n",
        "## First Benefit\n",
        "\n",
        "- These models do not process an input sequence token by token rather they take the entire sequence as input in one go which is a big improvement over RNN based models because now the model can be accelerated by the GPUs.\n",
        "\n",
        "## 2nd Benefit\n",
        "\n",
        "- We don’t need labeled data to pre-train these models. It means that we have to just provide a huge amount of unlabeled text data to train a transformer-based model. We can use this trained model for other NLP tasks like text classification, named entity recognition, text generation, etc. This is how transfer learning works in NLP.\n",
        "\n",
        "BERT and GPT-2 are the most popular transformer-based models and in this article, we will focus on BERT and learn how we can use a pre-trained BERT model to perform text classification.\n",
        "\n",
        "**Reference:**\n",
        "\n",
        "- [Analyticsvidya Blog - starter code](https://www.analyticsvidhya.com/blog/2020/07/transfer-learning-for-nlp-fine-tuning-bert-for-text-classification/)\n",
        "- [bert-sentiment - Abhishek Thakur](https://github.com/abhishekkrthakur/bert-sentiment/blob/master/train.py)\n",
        "\n",
        "\n",
        "# Why finetune language model:\n",
        "\n",
        "We often have large quantity of unlabelled dataset with only a small amount of labelled dataset.If we need to get accurate classification, we can use pretrained models trained on large corpus to get decent results. Generally, we use pretrained language models trained on large corpus to get embeddings and then mostly add a layer or two of neural networks on top to fit to our task in hand. This works very well until the data on which language model was trained is similar to our data. \n",
        "\n",
        "**Problem:** If our data is different than data used for pretraining, results would not be that satifactory. Consider for example if we have mix of Hindi and English language data and we are using pretrained model trained on Wikipedia, it would lead to bad results. \n",
        "\n",
        "**Solution:** In that scenario we need to fine-tune our language model too. As shown by Jeremy Howard and Sebastian Ruder in [Universal Language Model Fine-tuning for Text Classification](https://arxiv.org/abs/1801.06146), finetuning the language model can lead to performance enhancement. We generally modify the last few layers of language models to adapt to our data. This has been done and explained by Fast.ai in [Finetuning FastAI language model](https://nlp.fast.ai/classification/2018/05/15/introducing-ulmfit.html). They have done it extensively for `ULMFit`. We can follow the same approach with Bert and other models. With the revolution in NLP world, and with the arrival of beasts such as Bert, OpenAI-GPT, Elmo and so on we need a library which could help us keep up with this growing pace in NLP. Here comes in Hugging Face pytorch-transformers, a one stop for NLP. This is easy to use library to meet all your NLP requirements written in Pytorch. We will see how we can fine-tune Bert language model and then use that for SequenceClassification all using pytorch-transformers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVAMypjGTA-Z"
      },
      "source": [
        "# What is Model Fine-Tuning?\n",
        "\n",
        "BERT (Bidirectional Encoder Representations from Transformers) is a big neural network architecture, with a huge number of parameters, that can range from 100 million to over 300 million. So, training a BERT model from scratch on a small dataset would result in overfitting.\n",
        "\n",
        "So, it is better to use a pre-trained BERT model that was trained on a huge dataset, as a starting point. We can then further train the model on our relatively smaller dataset and this process is known as model fine-tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dIQAuAATJ0x"
      },
      "source": [
        "## Different Fine-Tuning Techniques\n",
        "\n",
        "- **Train the entire architecture** – We can further train the entire pre-trained model on our dataset and feed the output to a softmax layer. In this case, the error is back-propagated through the entire architecture and the pre-trained weights of the model are updated based on the new dataset.\n",
        "- **Train some layers while freezing others** – Another way to use a pre-trained model is to train it partially. What we can do is keep the weights of initial layers of the model frozen while we retrain only the higher layers. We can try and test as to how many layers to be frozen and how many to be trained.\n",
        "- **Freeze the entire architecture** – We can even freeze all the layers of the model and attach a few neural network layers of our own and train this new model. Note that the weights of only the attached layers will be updated during model training.\n",
        "\n",
        "In this tutorial, we will use the **second** approach. We will freeze all the layers of BERT except the last 2 layers during fine-tuning and append a dense layer and a softmax layer to the architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mNveTIzdP0G",
        "outputId": "0f907df9-aa41-4cef-b94a-e4a77801c686"
      },
      "source": [
        "! wget https://github.com/prateekjoshi565/Fine-Tuning-BERT/raw/master/spamdata_v2.csv"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-30 16:55:11--  https://github.com/prateekjoshi565/Fine-Tuning-BERT/raw/master/spamdata_v2.csv\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/prateekjoshi565/Fine-Tuning-BERT/master/spamdata_v2.csv [following]\n",
            "--2021-01-30 16:55:12--  https://raw.githubusercontent.com/prateekjoshi565/Fine-Tuning-BERT/master/spamdata_v2.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 467438 (456K) [text/plain]\n",
            "Saving to: ‘spamdata_v2.csv.2’\n",
            "\n",
            "spamdata_v2.csv.2   100%[===================>] 456.48K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-01-30 16:55:12 (36.6 MB/s) - ‘spamdata_v2.csv.2’ saved [467438/467438]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL2KYIDidd_I",
        "outputId": "d5161156-085b-42cc-9a59-597c0f13336c"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\t  spamdata_v2.csv    spamdata_v2.csv.2\n",
            "saved_weights.pt  spamdata_v2.csv.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szk60a0md2Is",
        "outputId": "c4028932-9813-4530-9ca1-e4994c8d134d"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsS2DcW0d_Nz"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdpZQMmKeCTC"
      },
      "source": [
        "df = pd.read_csv(\"spamdata_v2.csv\")"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "zPb-E3soeIoZ",
        "outputId": "4d30be1d-b28c-4171-86e2-315038d6237b"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               text\n",
              "0      0  Go until jurong point, crazy.. Available only ...\n",
              "1      0                      Ok lar... Joking wif u oni...\n",
              "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      0  U dun say so early hor... U c already then say...\n",
              "4      0  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn83usIBeKct",
        "outputId": "da0849df-c36b-4cf9-c094-14fb60380d31"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yLqlo7Fe4QC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHDUnda6e4R7",
        "outputId": "23d34dd1-03f5-4cc0-9484-589b2feeefec"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5PUSzdle4WG"
      },
      "source": [
        "# split train dataset into train, validation and test sets\n",
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'], \n",
        "                                                                    random_state=2018, \n",
        "                                                                    test_size=0.3, \n",
        "                                                                    stratify=df['label'])\n",
        "\n",
        "\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=2018, \n",
        "                                                                test_size=0.5, \n",
        "                                                                stratify=temp_labels)"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRtGQItle4X8"
      },
      "source": [
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1-L9Dzwr3al"
      },
      "source": [
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSjJzZYWr-mu"
      },
      "source": [
        "from prettytable import PrettyTable"
      ],
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "607YgVy2sWl6"
      },
      "source": [
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q31QSA39PhQo"
      },
      "source": [
        "## Count trainable parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hYerFsQsZEs",
        "outputId": "f65cbfd7-4655-423a-a887-bd8183e1b913"
      },
      "source": [
        "count_parameters(bert)\n"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------------------------------+------------+\n",
            "|                      Modules                       | Parameters |\n",
            "+----------------------------------------------------+------------+\n",
            "|         embeddings.word_embeddings.weight          |  23440896  |\n",
            "|       embeddings.position_embeddings.weight        |   393216   |\n",
            "|      embeddings.token_type_embeddings.weight       |    1536    |\n",
            "|            embeddings.LayerNorm.weight             |    768     |\n",
            "|             embeddings.LayerNorm.bias              |    768     |\n",
            "|    encoder.layer.0.attention.self.query.weight     |   589824   |\n",
            "|     encoder.layer.0.attention.self.query.bias      |    768     |\n",
            "|     encoder.layer.0.attention.self.key.weight      |   589824   |\n",
            "|      encoder.layer.0.attention.self.key.bias       |    768     |\n",
            "|    encoder.layer.0.attention.self.value.weight     |   589824   |\n",
            "|     encoder.layer.0.attention.self.value.bias      |    768     |\n",
            "|   encoder.layer.0.attention.output.dense.weight    |   589824   |\n",
            "|    encoder.layer.0.attention.output.dense.bias     |    768     |\n",
            "| encoder.layer.0.attention.output.LayerNorm.weight  |    768     |\n",
            "|  encoder.layer.0.attention.output.LayerNorm.bias   |    768     |\n",
            "|     encoder.layer.0.intermediate.dense.weight      |  2359296   |\n",
            "|      encoder.layer.0.intermediate.dense.bias       |    3072    |\n",
            "|        encoder.layer.0.output.dense.weight         |  2359296   |\n",
            "|         encoder.layer.0.output.dense.bias          |    768     |\n",
            "|      encoder.layer.0.output.LayerNorm.weight       |    768     |\n",
            "|       encoder.layer.0.output.LayerNorm.bias        |    768     |\n",
            "|    encoder.layer.1.attention.self.query.weight     |   589824   |\n",
            "|     encoder.layer.1.attention.self.query.bias      |    768     |\n",
            "|     encoder.layer.1.attention.self.key.weight      |   589824   |\n",
            "|      encoder.layer.1.attention.self.key.bias       |    768     |\n",
            "|    encoder.layer.1.attention.self.value.weight     |   589824   |\n",
            "|     encoder.layer.1.attention.self.value.bias      |    768     |\n",
            "|   encoder.layer.1.attention.output.dense.weight    |   589824   |\n",
            "|    encoder.layer.1.attention.output.dense.bias     |    768     |\n",
            "| encoder.layer.1.attention.output.LayerNorm.weight  |    768     |\n",
            "|  encoder.layer.1.attention.output.LayerNorm.bias   |    768     |\n",
            "|     encoder.layer.1.intermediate.dense.weight      |  2359296   |\n",
            "|      encoder.layer.1.intermediate.dense.bias       |    3072    |\n",
            "|        encoder.layer.1.output.dense.weight         |  2359296   |\n",
            "|         encoder.layer.1.output.dense.bias          |    768     |\n",
            "|      encoder.layer.1.output.LayerNorm.weight       |    768     |\n",
            "|       encoder.layer.1.output.LayerNorm.bias        |    768     |\n",
            "|    encoder.layer.2.attention.self.query.weight     |   589824   |\n",
            "|     encoder.layer.2.attention.self.query.bias      |    768     |\n",
            "|     encoder.layer.2.attention.self.key.weight      |   589824   |\n",
            "|      encoder.layer.2.attention.self.key.bias       |    768     |\n",
            "|    encoder.layer.2.attention.self.value.weight     |   589824   |\n",
            "|     encoder.layer.2.attention.self.value.bias      |    768     |\n",
            "|   encoder.layer.2.attention.output.dense.weight    |   589824   |\n",
            "|    encoder.layer.2.attention.output.dense.bias     |    768     |\n",
            "| encoder.layer.2.attention.output.LayerNorm.weight  |    768     |\n",
            "|  encoder.layer.2.attention.output.LayerNorm.bias   |    768     |\n",
            "|     encoder.layer.2.intermediate.dense.weight      |  2359296   |\n",
            "|      encoder.layer.2.intermediate.dense.bias       |    3072    |\n",
            "|        encoder.layer.2.output.dense.weight         |  2359296   |\n",
            "|         encoder.layer.2.output.dense.bias          |    768     |\n",
            "|      encoder.layer.2.output.LayerNorm.weight       |    768     |\n",
            "|       encoder.layer.2.output.LayerNorm.bias        |    768     |\n",
            "|    encoder.layer.3.attention.self.query.weight     |   589824   |\n",
            "|     encoder.layer.3.attention.self.query.bias      |    768     |\n",
            "|     encoder.layer.3.attention.self.key.weight      |   589824   |\n",
            "|      encoder.layer.3.attention.self.key.bias       |    768     |\n",
            "|    encoder.layer.3.attention.self.value.weight     |   589824   |\n",
            "|     encoder.layer.3.attention.self.value.bias      |    768     |\n",
            "|   encoder.layer.3.attention.output.dense.weight    |   589824   |\n",
            "|    encoder.layer.3.attention.output.dense.bias     |    768     |\n",
            "| encoder.layer.3.attention.output.LayerNorm.weight  |    768     |\n",
            "|  encoder.layer.3.attention.output.LayerNorm.bias   |    768     |\n",
            "|     encoder.layer.3.intermediate.dense.weight      |  2359296   |\n",
            "|      encoder.layer.3.intermediate.dense.bias       |    3072    |\n",
            "|        encoder.layer.3.output.dense.weight         |  2359296   |\n",
            "|         encoder.layer.3.output.dense.bias          |    768     |\n",
            "|      encoder.layer.3.output.LayerNorm.weight       |    768     |\n",
            "|       encoder.layer.3.output.LayerNorm.bias        |    768     |\n",
            "|    encoder.layer.4.attention.self.query.weight     |   589824   |\n",
            "|     encoder.layer.4.attention.self.query.bias      |    768     |\n",
            "|     encoder.layer.4.attention.self.key.weight      |   589824   |\n",
            "|      encoder.layer.4.attention.self.key.bias       |    768     |\n",
            "|    encoder.layer.4.attention.self.value.weight     |   589824   |\n",
            "|     encoder.layer.4.attention.self.value.bias      |    768     |\n",
            "|   encoder.layer.4.attention.output.dense.weight    |   589824   |\n",
            "|    encoder.layer.4.attention.output.dense.bias     |    768     |\n",
            "| encoder.layer.4.attention.output.LayerNorm.weight  |    768     |\n",
            "|  encoder.layer.4.attention.output.LayerNorm.bias   |    768     |\n",
            "|     encoder.layer.4.intermediate.dense.weight      |  2359296   |\n",
            "|      encoder.layer.4.intermediate.dense.bias       |    3072    |\n",
            "|        encoder.layer.4.output.dense.weight         |  2359296   |\n",
            "|         encoder.layer.4.output.dense.bias          |    768     |\n",
            "|      encoder.layer.4.output.LayerNorm.weight       |    768     |\n",
            "|       encoder.layer.4.output.LayerNorm.bias        |    768     |\n",
            "|    encoder.layer.5.attention.self.query.weight     |   589824   |\n",
            "|     encoder.layer.5.attention.self.query.bias      |    768     |\n",
            "|     encoder.layer.5.attention.self.key.weight      |   589824   |\n",
            "|      encoder.layer.5.attention.self.key.bias       |    768     |\n",
            "|    encoder.layer.5.attention.self.value.weight     |   589824   |\n",
            "|     encoder.layer.5.attention.self.value.bias      |    768     |\n",
            "|   encoder.layer.5.attention.output.dense.weight    |   589824   |\n",
            "|    encoder.layer.5.attention.output.dense.bias     |    768     |\n",
            "| encoder.layer.5.attention.output.LayerNorm.weight  |    768     |\n",
            "|  encoder.layer.5.attention.output.LayerNorm.bias   |    768     |\n",
            "|     encoder.layer.5.intermediate.dense.weight      |  2359296   |\n",
            "|      encoder.layer.5.intermediate.dense.bias       |    3072    |\n",
            "|        encoder.layer.5.output.dense.weight         |  2359296   |\n",
            "|         encoder.layer.5.output.dense.bias          |    768     |\n",
            "|      encoder.layer.5.output.LayerNorm.weight       |    768     |\n",
            "|       encoder.layer.5.output.LayerNorm.bias        |    768     |\n",
            "|    encoder.layer.6.attention.self.query.weight     |   589824   |\n",
            "|     encoder.layer.6.attention.self.query.bias      |    768     |\n",
            "|     encoder.layer.6.attention.self.key.weight      |   589824   |\n",
            "|      encoder.layer.6.attention.self.key.bias       |    768     |\n",
            "|    encoder.layer.6.attention.self.value.weight     |   589824   |\n",
            "|     encoder.layer.6.attention.self.value.bias      |    768     |\n",
            "|   encoder.layer.6.attention.output.dense.weight    |   589824   |\n",
            "|    encoder.layer.6.attention.output.dense.bias     |    768     |\n",
            "| encoder.layer.6.attention.output.LayerNorm.weight  |    768     |\n",
            "|  encoder.layer.6.attention.output.LayerNorm.bias   |    768     |\n",
            "|     encoder.layer.6.intermediate.dense.weight      |  2359296   |\n",
            "|      encoder.layer.6.intermediate.dense.bias       |    3072    |\n",
            "|        encoder.layer.6.output.dense.weight         |  2359296   |\n",
            "|         encoder.layer.6.output.dense.bias          |    768     |\n",
            "|      encoder.layer.6.output.LayerNorm.weight       |    768     |\n",
            "|       encoder.layer.6.output.LayerNorm.bias        |    768     |\n",
            "|    encoder.layer.7.attention.self.query.weight     |   589824   |\n",
            "|     encoder.layer.7.attention.self.query.bias      |    768     |\n",
            "|     encoder.layer.7.attention.self.key.weight      |   589824   |\n",
            "|      encoder.layer.7.attention.self.key.bias       |    768     |\n",
            "|    encoder.layer.7.attention.self.value.weight     |   589824   |\n",
            "|     encoder.layer.7.attention.self.value.bias      |    768     |\n",
            "|   encoder.layer.7.attention.output.dense.weight    |   589824   |\n",
            "|    encoder.layer.7.attention.output.dense.bias     |    768     |\n",
            "| encoder.layer.7.attention.output.LayerNorm.weight  |    768     |\n",
            "|  encoder.layer.7.attention.output.LayerNorm.bias   |    768     |\n",
            "|     encoder.layer.7.intermediate.dense.weight      |  2359296   |\n",
            "|      encoder.layer.7.intermediate.dense.bias       |    3072    |\n",
            "|        encoder.layer.7.output.dense.weight         |  2359296   |\n",
            "|         encoder.layer.7.output.dense.bias          |    768     |\n",
            "|      encoder.layer.7.output.LayerNorm.weight       |    768     |\n",
            "|       encoder.layer.7.output.LayerNorm.bias        |    768     |\n",
            "|    encoder.layer.8.attention.self.query.weight     |   589824   |\n",
            "|     encoder.layer.8.attention.self.query.bias      |    768     |\n",
            "|     encoder.layer.8.attention.self.key.weight      |   589824   |\n",
            "|      encoder.layer.8.attention.self.key.bias       |    768     |\n",
            "|    encoder.layer.8.attention.self.value.weight     |   589824   |\n",
            "|     encoder.layer.8.attention.self.value.bias      |    768     |\n",
            "|   encoder.layer.8.attention.output.dense.weight    |   589824   |\n",
            "|    encoder.layer.8.attention.output.dense.bias     |    768     |\n",
            "| encoder.layer.8.attention.output.LayerNorm.weight  |    768     |\n",
            "|  encoder.layer.8.attention.output.LayerNorm.bias   |    768     |\n",
            "|     encoder.layer.8.intermediate.dense.weight      |  2359296   |\n",
            "|      encoder.layer.8.intermediate.dense.bias       |    3072    |\n",
            "|        encoder.layer.8.output.dense.weight         |  2359296   |\n",
            "|         encoder.layer.8.output.dense.bias          |    768     |\n",
            "|      encoder.layer.8.output.LayerNorm.weight       |    768     |\n",
            "|       encoder.layer.8.output.LayerNorm.bias        |    768     |\n",
            "|    encoder.layer.9.attention.self.query.weight     |   589824   |\n",
            "|     encoder.layer.9.attention.self.query.bias      |    768     |\n",
            "|     encoder.layer.9.attention.self.key.weight      |   589824   |\n",
            "|      encoder.layer.9.attention.self.key.bias       |    768     |\n",
            "|    encoder.layer.9.attention.self.value.weight     |   589824   |\n",
            "|     encoder.layer.9.attention.self.value.bias      |    768     |\n",
            "|   encoder.layer.9.attention.output.dense.weight    |   589824   |\n",
            "|    encoder.layer.9.attention.output.dense.bias     |    768     |\n",
            "| encoder.layer.9.attention.output.LayerNorm.weight  |    768     |\n",
            "|  encoder.layer.9.attention.output.LayerNorm.bias   |    768     |\n",
            "|     encoder.layer.9.intermediate.dense.weight      |  2359296   |\n",
            "|      encoder.layer.9.intermediate.dense.bias       |    3072    |\n",
            "|        encoder.layer.9.output.dense.weight         |  2359296   |\n",
            "|         encoder.layer.9.output.dense.bias          |    768     |\n",
            "|      encoder.layer.9.output.LayerNorm.weight       |    768     |\n",
            "|       encoder.layer.9.output.LayerNorm.bias        |    768     |\n",
            "|    encoder.layer.10.attention.self.query.weight    |   589824   |\n",
            "|     encoder.layer.10.attention.self.query.bias     |    768     |\n",
            "|     encoder.layer.10.attention.self.key.weight     |   589824   |\n",
            "|      encoder.layer.10.attention.self.key.bias      |    768     |\n",
            "|    encoder.layer.10.attention.self.value.weight    |   589824   |\n",
            "|     encoder.layer.10.attention.self.value.bias     |    768     |\n",
            "|   encoder.layer.10.attention.output.dense.weight   |   589824   |\n",
            "|    encoder.layer.10.attention.output.dense.bias    |    768     |\n",
            "| encoder.layer.10.attention.output.LayerNorm.weight |    768     |\n",
            "|  encoder.layer.10.attention.output.LayerNorm.bias  |    768     |\n",
            "|     encoder.layer.10.intermediate.dense.weight     |  2359296   |\n",
            "|      encoder.layer.10.intermediate.dense.bias      |    3072    |\n",
            "|        encoder.layer.10.output.dense.weight        |  2359296   |\n",
            "|         encoder.layer.10.output.dense.bias         |    768     |\n",
            "|      encoder.layer.10.output.LayerNorm.weight      |    768     |\n",
            "|       encoder.layer.10.output.LayerNorm.bias       |    768     |\n",
            "|    encoder.layer.11.attention.self.query.weight    |   589824   |\n",
            "|     encoder.layer.11.attention.self.query.bias     |    768     |\n",
            "|     encoder.layer.11.attention.self.key.weight     |   589824   |\n",
            "|      encoder.layer.11.attention.self.key.bias      |    768     |\n",
            "|    encoder.layer.11.attention.self.value.weight    |   589824   |\n",
            "|     encoder.layer.11.attention.self.value.bias     |    768     |\n",
            "|   encoder.layer.11.attention.output.dense.weight   |   589824   |\n",
            "|    encoder.layer.11.attention.output.dense.bias    |    768     |\n",
            "| encoder.layer.11.attention.output.LayerNorm.weight |    768     |\n",
            "|  encoder.layer.11.attention.output.LayerNorm.bias  |    768     |\n",
            "|     encoder.layer.11.intermediate.dense.weight     |  2359296   |\n",
            "|      encoder.layer.11.intermediate.dense.bias      |    3072    |\n",
            "|        encoder.layer.11.output.dense.weight        |  2359296   |\n",
            "|         encoder.layer.11.output.dense.bias         |    768     |\n",
            "|      encoder.layer.11.output.LayerNorm.weight      |    768     |\n",
            "|       encoder.layer.11.output.LayerNorm.bias       |    768     |\n",
            "|                pooler.dense.weight                 |   589824   |\n",
            "|                 pooler.dense.bias                  |    768     |\n",
            "+----------------------------------------------------+------------+\n",
            "Total Trainable Params: 109482240\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "109482240"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh24n-_gxHH1"
      },
      "source": [
        "Let’s see how this BERT tokenizer works. We will try to encode a couple of sentences using the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBDBbxLdtIXh",
        "outputId": "66a89e43-e636-4765-8e53-54d6e45c97ac"
      },
      "source": [
        "# sample data\n",
        "text = [\"we will fine-tune a bert model\"]\n",
        "\n",
        "# encode text\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True)\n",
        "\n",
        "# output\n",
        "print(sent_id)"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': [[101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Om-lw-pDxTcL",
        "outputId": "4ff20009-725e-443f-f656-a66da693d6f4"
      },
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30);"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aurnpjbIxtV3",
        "outputId": "01fe5fc6-5936-4c0a-e0d7-043c5c08c6e4"
      },
      "source": [
        "train_text"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1188    All will come alive.better correct any good lo...\n",
              "5403             So gd got free ice cream... I oso wan...\n",
              "2924                     Are you coming to day for class.\n",
              "880     Reminder: You have not downloaded the content ...\n",
              "719     Macha dont feel upset.i can assume your mindse...\n",
              "                              ...                        \n",
              "5121                     Oops I did have it,  &lt;#&gt; ?\n",
              "1006    Panasonic & BluetoothHdset FREE. Nokia FREE. M...\n",
              "4374    Ur TONEXS subscription has been renewed and yo...\n",
              "903     Lovely smell on this bus and it ain't tobacco... \n",
              "5057    Geeeee ... Your internet is really bad today, ...\n",
              "Name: text, Length: 3900, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inu_BdT7xh-e",
        "outputId": "46780c79-e102-4afa-efed-ce7753ae4ed1"
      },
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = 25,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = 25,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = 25,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqELYxSSyNPB",
        "outputId": "dc892af2-9520-493e-fe92-b2169861c906"
      },
      "source": [
        "tokens_train.keys()"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkll0vq4yTFz"
      },
      "source": [
        "## convert lists to tensors\n",
        "\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_token_ids = torch.tensor(tokens_train['token_type_ids'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_token_ids = torch.tensor(tokens_val['token_type_ids'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_token_ids = torch.tensor(tokens_test['token_type_ids'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RcBTHfhynDj"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_token_ids, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_token_ids, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoYE91PxPyYA"
      },
      "source": [
        "# Check different pre-trained layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQFLE2RJy5Br",
        "outputId": "4794af02-70c3-4216-b023-d6e90d84bd8c"
      },
      "source": [
        "for name, param in bert.named_parameters():\n",
        "    print(f\"layer name: {name}, require grad: {param.requires_grad}\")"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer name: embeddings.word_embeddings.weight, require grad: True\n",
            "layer name: embeddings.position_embeddings.weight, require grad: True\n",
            "layer name: embeddings.token_type_embeddings.weight, require grad: True\n",
            "layer name: embeddings.LayerNorm.weight, require grad: True\n",
            "layer name: embeddings.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.0.attention.self.query.weight, require grad: True\n",
            "layer name: encoder.layer.0.attention.self.query.bias, require grad: True\n",
            "layer name: encoder.layer.0.attention.self.key.weight, require grad: True\n",
            "layer name: encoder.layer.0.attention.self.key.bias, require grad: True\n",
            "layer name: encoder.layer.0.attention.self.value.weight, require grad: True\n",
            "layer name: encoder.layer.0.attention.self.value.bias, require grad: True\n",
            "layer name: encoder.layer.0.attention.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.0.attention.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.0.attention.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.0.attention.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.0.intermediate.dense.weight, require grad: True\n",
            "layer name: encoder.layer.0.intermediate.dense.bias, require grad: True\n",
            "layer name: encoder.layer.0.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.0.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.0.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.0.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.1.attention.self.query.weight, require grad: True\n",
            "layer name: encoder.layer.1.attention.self.query.bias, require grad: True\n",
            "layer name: encoder.layer.1.attention.self.key.weight, require grad: True\n",
            "layer name: encoder.layer.1.attention.self.key.bias, require grad: True\n",
            "layer name: encoder.layer.1.attention.self.value.weight, require grad: True\n",
            "layer name: encoder.layer.1.attention.self.value.bias, require grad: True\n",
            "layer name: encoder.layer.1.attention.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.1.attention.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.1.attention.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.1.attention.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.1.intermediate.dense.weight, require grad: True\n",
            "layer name: encoder.layer.1.intermediate.dense.bias, require grad: True\n",
            "layer name: encoder.layer.1.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.1.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.1.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.1.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.2.attention.self.query.weight, require grad: True\n",
            "layer name: encoder.layer.2.attention.self.query.bias, require grad: True\n",
            "layer name: encoder.layer.2.attention.self.key.weight, require grad: True\n",
            "layer name: encoder.layer.2.attention.self.key.bias, require grad: True\n",
            "layer name: encoder.layer.2.attention.self.value.weight, require grad: True\n",
            "layer name: encoder.layer.2.attention.self.value.bias, require grad: True\n",
            "layer name: encoder.layer.2.attention.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.2.attention.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.2.attention.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.2.attention.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.2.intermediate.dense.weight, require grad: True\n",
            "layer name: encoder.layer.2.intermediate.dense.bias, require grad: True\n",
            "layer name: encoder.layer.2.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.2.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.2.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.2.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.3.attention.self.query.weight, require grad: True\n",
            "layer name: encoder.layer.3.attention.self.query.bias, require grad: True\n",
            "layer name: encoder.layer.3.attention.self.key.weight, require grad: True\n",
            "layer name: encoder.layer.3.attention.self.key.bias, require grad: True\n",
            "layer name: encoder.layer.3.attention.self.value.weight, require grad: True\n",
            "layer name: encoder.layer.3.attention.self.value.bias, require grad: True\n",
            "layer name: encoder.layer.3.attention.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.3.attention.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.3.attention.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.3.attention.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.3.intermediate.dense.weight, require grad: True\n",
            "layer name: encoder.layer.3.intermediate.dense.bias, require grad: True\n",
            "layer name: encoder.layer.3.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.3.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.3.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.3.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.4.attention.self.query.weight, require grad: True\n",
            "layer name: encoder.layer.4.attention.self.query.bias, require grad: True\n",
            "layer name: encoder.layer.4.attention.self.key.weight, require grad: True\n",
            "layer name: encoder.layer.4.attention.self.key.bias, require grad: True\n",
            "layer name: encoder.layer.4.attention.self.value.weight, require grad: True\n",
            "layer name: encoder.layer.4.attention.self.value.bias, require grad: True\n",
            "layer name: encoder.layer.4.attention.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.4.attention.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.4.attention.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.4.attention.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.4.intermediate.dense.weight, require grad: True\n",
            "layer name: encoder.layer.4.intermediate.dense.bias, require grad: True\n",
            "layer name: encoder.layer.4.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.4.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.4.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.4.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.5.attention.self.query.weight, require grad: True\n",
            "layer name: encoder.layer.5.attention.self.query.bias, require grad: True\n",
            "layer name: encoder.layer.5.attention.self.key.weight, require grad: True\n",
            "layer name: encoder.layer.5.attention.self.key.bias, require grad: True\n",
            "layer name: encoder.layer.5.attention.self.value.weight, require grad: True\n",
            "layer name: encoder.layer.5.attention.self.value.bias, require grad: True\n",
            "layer name: encoder.layer.5.attention.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.5.attention.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.5.attention.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.5.attention.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.5.intermediate.dense.weight, require grad: True\n",
            "layer name: encoder.layer.5.intermediate.dense.bias, require grad: True\n",
            "layer name: encoder.layer.5.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.5.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.5.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.5.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.6.attention.self.query.weight, require grad: True\n",
            "layer name: encoder.layer.6.attention.self.query.bias, require grad: True\n",
            "layer name: encoder.layer.6.attention.self.key.weight, require grad: True\n",
            "layer name: encoder.layer.6.attention.self.key.bias, require grad: True\n",
            "layer name: encoder.layer.6.attention.self.value.weight, require grad: True\n",
            "layer name: encoder.layer.6.attention.self.value.bias, require grad: True\n",
            "layer name: encoder.layer.6.attention.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.6.attention.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.6.attention.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.6.attention.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.6.intermediate.dense.weight, require grad: True\n",
            "layer name: encoder.layer.6.intermediate.dense.bias, require grad: True\n",
            "layer name: encoder.layer.6.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.6.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.6.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.6.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.7.attention.self.query.weight, require grad: True\n",
            "layer name: encoder.layer.7.attention.self.query.bias, require grad: True\n",
            "layer name: encoder.layer.7.attention.self.key.weight, require grad: True\n",
            "layer name: encoder.layer.7.attention.self.key.bias, require grad: True\n",
            "layer name: encoder.layer.7.attention.self.value.weight, require grad: True\n",
            "layer name: encoder.layer.7.attention.self.value.bias, require grad: True\n",
            "layer name: encoder.layer.7.attention.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.7.attention.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.7.attention.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.7.attention.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.7.intermediate.dense.weight, require grad: True\n",
            "layer name: encoder.layer.7.intermediate.dense.bias, require grad: True\n",
            "layer name: encoder.layer.7.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.7.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.7.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.7.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.8.attention.self.query.weight, require grad: True\n",
            "layer name: encoder.layer.8.attention.self.query.bias, require grad: True\n",
            "layer name: encoder.layer.8.attention.self.key.weight, require grad: True\n",
            "layer name: encoder.layer.8.attention.self.key.bias, require grad: True\n",
            "layer name: encoder.layer.8.attention.self.value.weight, require grad: True\n",
            "layer name: encoder.layer.8.attention.self.value.bias, require grad: True\n",
            "layer name: encoder.layer.8.attention.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.8.attention.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.8.attention.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.8.attention.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.8.intermediate.dense.weight, require grad: True\n",
            "layer name: encoder.layer.8.intermediate.dense.bias, require grad: True\n",
            "layer name: encoder.layer.8.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.8.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.8.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.8.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.9.attention.self.query.weight, require grad: True\n",
            "layer name: encoder.layer.9.attention.self.query.bias, require grad: True\n",
            "layer name: encoder.layer.9.attention.self.key.weight, require grad: True\n",
            "layer name: encoder.layer.9.attention.self.key.bias, require grad: True\n",
            "layer name: encoder.layer.9.attention.self.value.weight, require grad: True\n",
            "layer name: encoder.layer.9.attention.self.value.bias, require grad: True\n",
            "layer name: encoder.layer.9.attention.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.9.attention.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.9.attention.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.9.attention.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.9.intermediate.dense.weight, require grad: True\n",
            "layer name: encoder.layer.9.intermediate.dense.bias, require grad: True\n",
            "layer name: encoder.layer.9.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.9.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.9.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.9.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.10.attention.self.query.weight, require grad: True\n",
            "layer name: encoder.layer.10.attention.self.query.bias, require grad: True\n",
            "layer name: encoder.layer.10.attention.self.key.weight, require grad: True\n",
            "layer name: encoder.layer.10.attention.self.key.bias, require grad: True\n",
            "layer name: encoder.layer.10.attention.self.value.weight, require grad: True\n",
            "layer name: encoder.layer.10.attention.self.value.bias, require grad: True\n",
            "layer name: encoder.layer.10.attention.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.10.attention.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.10.attention.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.10.attention.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.10.intermediate.dense.weight, require grad: True\n",
            "layer name: encoder.layer.10.intermediate.dense.bias, require grad: True\n",
            "layer name: encoder.layer.10.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.10.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.10.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.10.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.11.attention.self.query.weight, require grad: True\n",
            "layer name: encoder.layer.11.attention.self.query.bias, require grad: True\n",
            "layer name: encoder.layer.11.attention.self.key.weight, require grad: True\n",
            "layer name: encoder.layer.11.attention.self.key.bias, require grad: True\n",
            "layer name: encoder.layer.11.attention.self.value.weight, require grad: True\n",
            "layer name: encoder.layer.11.attention.self.value.bias, require grad: True\n",
            "layer name: encoder.layer.11.attention.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.11.attention.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.11.attention.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.11.attention.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.11.intermediate.dense.weight, require grad: True\n",
            "layer name: encoder.layer.11.intermediate.dense.bias, require grad: True\n",
            "layer name: encoder.layer.11.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.11.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.11.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.11.output.LayerNorm.bias, require grad: True\n",
            "layer name: pooler.dense.weight, require grad: True\n",
            "layer name: pooler.dense.bias, require grad: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4sVZMfCP32j"
      },
      "source": [
        "# Weight Retraining and Finetuning\n",
        "\n",
        "Note: All layers are set to `require grad: True` i.e trainable.\n",
        "\n",
        "- Now we want to freeze upto layers 0 to 9\n",
        "- retrain weights for layer 10 and 11"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP7X7EUyzBC9"
      },
      "source": [
        "# freeze all the parameters except the last 1 layer\n",
        "for name, param in bert.named_parameters():\n",
        "    if 'layer.11' not in name and 'layer.10' not in name:\n",
        "        param.requires_grad = False"
      ],
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTq7Oz6v1XHc",
        "outputId": "b38a9c37-e78a-4e62-a23d-af7dfe8408cd"
      },
      "source": [
        "for name, param in bert.named_parameters():\n",
        "    print(f\"layer name: {name}, require grad: {param.requires_grad}\")"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer name: embeddings.word_embeddings.weight, require grad: False\n",
            "layer name: embeddings.position_embeddings.weight, require grad: False\n",
            "layer name: embeddings.token_type_embeddings.weight, require grad: False\n",
            "layer name: embeddings.LayerNorm.weight, require grad: False\n",
            "layer name: embeddings.LayerNorm.bias, require grad: False\n",
            "layer name: encoder.layer.0.attention.self.query.weight, require grad: False\n",
            "layer name: encoder.layer.0.attention.self.query.bias, require grad: False\n",
            "layer name: encoder.layer.0.attention.self.key.weight, require grad: False\n",
            "layer name: encoder.layer.0.attention.self.key.bias, require grad: False\n",
            "layer name: encoder.layer.0.attention.self.value.weight, require grad: False\n",
            "layer name: encoder.layer.0.attention.self.value.bias, require grad: False\n",
            "layer name: encoder.layer.0.attention.output.dense.weight, require grad: False\n",
            "layer name: encoder.layer.0.attention.output.dense.bias, require grad: False\n",
            "layer name: encoder.layer.0.attention.output.LayerNorm.weight, require grad: False\n",
            "layer name: encoder.layer.0.attention.output.LayerNorm.bias, require grad: False\n",
            "layer name: encoder.layer.0.intermediate.dense.weight, require grad: False\n",
            "layer name: encoder.layer.0.intermediate.dense.bias, require grad: False\n",
            "layer name: encoder.layer.0.output.dense.weight, require grad: False\n",
            "layer name: encoder.layer.0.output.dense.bias, require grad: False\n",
            "layer name: encoder.layer.0.output.LayerNorm.weight, require grad: False\n",
            "layer name: encoder.layer.0.output.LayerNorm.bias, require grad: False\n",
            "layer name: encoder.layer.1.attention.self.query.weight, require grad: False\n",
            "layer name: encoder.layer.1.attention.self.query.bias, require grad: False\n",
            "layer name: encoder.layer.1.attention.self.key.weight, require grad: False\n",
            "layer name: encoder.layer.1.attention.self.key.bias, require grad: False\n",
            "layer name: encoder.layer.1.attention.self.value.weight, require grad: False\n",
            "layer name: encoder.layer.1.attention.self.value.bias, require grad: False\n",
            "layer name: encoder.layer.1.attention.output.dense.weight, require grad: False\n",
            "layer name: encoder.layer.1.attention.output.dense.bias, require grad: False\n",
            "layer name: encoder.layer.1.attention.output.LayerNorm.weight, require grad: False\n",
            "layer name: encoder.layer.1.attention.output.LayerNorm.bias, require grad: False\n",
            "layer name: encoder.layer.1.intermediate.dense.weight, require grad: False\n",
            "layer name: encoder.layer.1.intermediate.dense.bias, require grad: False\n",
            "layer name: encoder.layer.1.output.dense.weight, require grad: False\n",
            "layer name: encoder.layer.1.output.dense.bias, require grad: False\n",
            "layer name: encoder.layer.1.output.LayerNorm.weight, require grad: False\n",
            "layer name: encoder.layer.1.output.LayerNorm.bias, require grad: False\n",
            "layer name: encoder.layer.2.attention.self.query.weight, require grad: False\n",
            "layer name: encoder.layer.2.attention.self.query.bias, require grad: False\n",
            "layer name: encoder.layer.2.attention.self.key.weight, require grad: False\n",
            "layer name: encoder.layer.2.attention.self.key.bias, require grad: False\n",
            "layer name: encoder.layer.2.attention.self.value.weight, require grad: False\n",
            "layer name: encoder.layer.2.attention.self.value.bias, require grad: False\n",
            "layer name: encoder.layer.2.attention.output.dense.weight, require grad: False\n",
            "layer name: encoder.layer.2.attention.output.dense.bias, require grad: False\n",
            "layer name: encoder.layer.2.attention.output.LayerNorm.weight, require grad: False\n",
            "layer name: encoder.layer.2.attention.output.LayerNorm.bias, require grad: False\n",
            "layer name: encoder.layer.2.intermediate.dense.weight, require grad: False\n",
            "layer name: encoder.layer.2.intermediate.dense.bias, require grad: False\n",
            "layer name: encoder.layer.2.output.dense.weight, require grad: False\n",
            "layer name: encoder.layer.2.output.dense.bias, require grad: False\n",
            "layer name: encoder.layer.2.output.LayerNorm.weight, require grad: False\n",
            "layer name: encoder.layer.2.output.LayerNorm.bias, require grad: False\n",
            "layer name: encoder.layer.3.attention.self.query.weight, require grad: False\n",
            "layer name: encoder.layer.3.attention.self.query.bias, require grad: False\n",
            "layer name: encoder.layer.3.attention.self.key.weight, require grad: False\n",
            "layer name: encoder.layer.3.attention.self.key.bias, require grad: False\n",
            "layer name: encoder.layer.3.attention.self.value.weight, require grad: False\n",
            "layer name: encoder.layer.3.attention.self.value.bias, require grad: False\n",
            "layer name: encoder.layer.3.attention.output.dense.weight, require grad: False\n",
            "layer name: encoder.layer.3.attention.output.dense.bias, require grad: False\n",
            "layer name: encoder.layer.3.attention.output.LayerNorm.weight, require grad: False\n",
            "layer name: encoder.layer.3.attention.output.LayerNorm.bias, require grad: False\n",
            "layer name: encoder.layer.3.intermediate.dense.weight, require grad: False\n",
            "layer name: encoder.layer.3.intermediate.dense.bias, require grad: False\n",
            "layer name: encoder.layer.3.output.dense.weight, require grad: False\n",
            "layer name: encoder.layer.3.output.dense.bias, require grad: False\n",
            "layer name: encoder.layer.3.output.LayerNorm.weight, require grad: False\n",
            "layer name: encoder.layer.3.output.LayerNorm.bias, require grad: False\n",
            "layer name: encoder.layer.4.attention.self.query.weight, require grad: False\n",
            "layer name: encoder.layer.4.attention.self.query.bias, require grad: False\n",
            "layer name: encoder.layer.4.attention.self.key.weight, require grad: False\n",
            "layer name: encoder.layer.4.attention.self.key.bias, require grad: False\n",
            "layer name: encoder.layer.4.attention.self.value.weight, require grad: False\n",
            "layer name: encoder.layer.4.attention.self.value.bias, require grad: False\n",
            "layer name: encoder.layer.4.attention.output.dense.weight, require grad: False\n",
            "layer name: encoder.layer.4.attention.output.dense.bias, require grad: False\n",
            "layer name: encoder.layer.4.attention.output.LayerNorm.weight, require grad: False\n",
            "layer name: encoder.layer.4.attention.output.LayerNorm.bias, require grad: False\n",
            "layer name: encoder.layer.4.intermediate.dense.weight, require grad: False\n",
            "layer name: encoder.layer.4.intermediate.dense.bias, require grad: False\n",
            "layer name: encoder.layer.4.output.dense.weight, require grad: False\n",
            "layer name: encoder.layer.4.output.dense.bias, require grad: False\n",
            "layer name: encoder.layer.4.output.LayerNorm.weight, require grad: False\n",
            "layer name: encoder.layer.4.output.LayerNorm.bias, require grad: False\n",
            "layer name: encoder.layer.5.attention.self.query.weight, require grad: False\n",
            "layer name: encoder.layer.5.attention.self.query.bias, require grad: False\n",
            "layer name: encoder.layer.5.attention.self.key.weight, require grad: False\n",
            "layer name: encoder.layer.5.attention.self.key.bias, require grad: False\n",
            "layer name: encoder.layer.5.attention.self.value.weight, require grad: False\n",
            "layer name: encoder.layer.5.attention.self.value.bias, require grad: False\n",
            "layer name: encoder.layer.5.attention.output.dense.weight, require grad: False\n",
            "layer name: encoder.layer.5.attention.output.dense.bias, require grad: False\n",
            "layer name: encoder.layer.5.attention.output.LayerNorm.weight, require grad: False\n",
            "layer name: encoder.layer.5.attention.output.LayerNorm.bias, require grad: False\n",
            "layer name: encoder.layer.5.intermediate.dense.weight, require grad: False\n",
            "layer name: encoder.layer.5.intermediate.dense.bias, require grad: False\n",
            "layer name: encoder.layer.5.output.dense.weight, require grad: False\n",
            "layer name: encoder.layer.5.output.dense.bias, require grad: False\n",
            "layer name: encoder.layer.5.output.LayerNorm.weight, require grad: False\n",
            "layer name: encoder.layer.5.output.LayerNorm.bias, require grad: False\n",
            "layer name: encoder.layer.6.attention.self.query.weight, require grad: False\n",
            "layer name: encoder.layer.6.attention.self.query.bias, require grad: False\n",
            "layer name: encoder.layer.6.attention.self.key.weight, require grad: False\n",
            "layer name: encoder.layer.6.attention.self.key.bias, require grad: False\n",
            "layer name: encoder.layer.6.attention.self.value.weight, require grad: False\n",
            "layer name: encoder.layer.6.attention.self.value.bias, require grad: False\n",
            "layer name: encoder.layer.6.attention.output.dense.weight, require grad: False\n",
            "layer name: encoder.layer.6.attention.output.dense.bias, require grad: False\n",
            "layer name: encoder.layer.6.attention.output.LayerNorm.weight, require grad: False\n",
            "layer name: encoder.layer.6.attention.output.LayerNorm.bias, require grad: False\n",
            "layer name: encoder.layer.6.intermediate.dense.weight, require grad: False\n",
            "layer name: encoder.layer.6.intermediate.dense.bias, require grad: False\n",
            "layer name: encoder.layer.6.output.dense.weight, require grad: False\n",
            "layer name: encoder.layer.6.output.dense.bias, require grad: False\n",
            "layer name: encoder.layer.6.output.LayerNorm.weight, require grad: False\n",
            "layer name: encoder.layer.6.output.LayerNorm.bias, require grad: False\n",
            "layer name: encoder.layer.7.attention.self.query.weight, require grad: False\n",
            "layer name: encoder.layer.7.attention.self.query.bias, require grad: False\n",
            "layer name: encoder.layer.7.attention.self.key.weight, require grad: False\n",
            "layer name: encoder.layer.7.attention.self.key.bias, require grad: False\n",
            "layer name: encoder.layer.7.attention.self.value.weight, require grad: False\n",
            "layer name: encoder.layer.7.attention.self.value.bias, require grad: False\n",
            "layer name: encoder.layer.7.attention.output.dense.weight, require grad: False\n",
            "layer name: encoder.layer.7.attention.output.dense.bias, require grad: False\n",
            "layer name: encoder.layer.7.attention.output.LayerNorm.weight, require grad: False\n",
            "layer name: encoder.layer.7.attention.output.LayerNorm.bias, require grad: False\n",
            "layer name: encoder.layer.7.intermediate.dense.weight, require grad: False\n",
            "layer name: encoder.layer.7.intermediate.dense.bias, require grad: False\n",
            "layer name: encoder.layer.7.output.dense.weight, require grad: False\n",
            "layer name: encoder.layer.7.output.dense.bias, require grad: False\n",
            "layer name: encoder.layer.7.output.LayerNorm.weight, require grad: False\n",
            "layer name: encoder.layer.7.output.LayerNorm.bias, require grad: False\n",
            "layer name: encoder.layer.8.attention.self.query.weight, require grad: False\n",
            "layer name: encoder.layer.8.attention.self.query.bias, require grad: False\n",
            "layer name: encoder.layer.8.attention.self.key.weight, require grad: False\n",
            "layer name: encoder.layer.8.attention.self.key.bias, require grad: False\n",
            "layer name: encoder.layer.8.attention.self.value.weight, require grad: False\n",
            "layer name: encoder.layer.8.attention.self.value.bias, require grad: False\n",
            "layer name: encoder.layer.8.attention.output.dense.weight, require grad: False\n",
            "layer name: encoder.layer.8.attention.output.dense.bias, require grad: False\n",
            "layer name: encoder.layer.8.attention.output.LayerNorm.weight, require grad: False\n",
            "layer name: encoder.layer.8.attention.output.LayerNorm.bias, require grad: False\n",
            "layer name: encoder.layer.8.intermediate.dense.weight, require grad: False\n",
            "layer name: encoder.layer.8.intermediate.dense.bias, require grad: False\n",
            "layer name: encoder.layer.8.output.dense.weight, require grad: False\n",
            "layer name: encoder.layer.8.output.dense.bias, require grad: False\n",
            "layer name: encoder.layer.8.output.LayerNorm.weight, require grad: False\n",
            "layer name: encoder.layer.8.output.LayerNorm.bias, require grad: False\n",
            "layer name: encoder.layer.9.attention.self.query.weight, require grad: False\n",
            "layer name: encoder.layer.9.attention.self.query.bias, require grad: False\n",
            "layer name: encoder.layer.9.attention.self.key.weight, require grad: False\n",
            "layer name: encoder.layer.9.attention.self.key.bias, require grad: False\n",
            "layer name: encoder.layer.9.attention.self.value.weight, require grad: False\n",
            "layer name: encoder.layer.9.attention.self.value.bias, require grad: False\n",
            "layer name: encoder.layer.9.attention.output.dense.weight, require grad: False\n",
            "layer name: encoder.layer.9.attention.output.dense.bias, require grad: False\n",
            "layer name: encoder.layer.9.attention.output.LayerNorm.weight, require grad: False\n",
            "layer name: encoder.layer.9.attention.output.LayerNorm.bias, require grad: False\n",
            "layer name: encoder.layer.9.intermediate.dense.weight, require grad: False\n",
            "layer name: encoder.layer.9.intermediate.dense.bias, require grad: False\n",
            "layer name: encoder.layer.9.output.dense.weight, require grad: False\n",
            "layer name: encoder.layer.9.output.dense.bias, require grad: False\n",
            "layer name: encoder.layer.9.output.LayerNorm.weight, require grad: False\n",
            "layer name: encoder.layer.9.output.LayerNorm.bias, require grad: False\n",
            "layer name: encoder.layer.10.attention.self.query.weight, require grad: True\n",
            "layer name: encoder.layer.10.attention.self.query.bias, require grad: True\n",
            "layer name: encoder.layer.10.attention.self.key.weight, require grad: True\n",
            "layer name: encoder.layer.10.attention.self.key.bias, require grad: True\n",
            "layer name: encoder.layer.10.attention.self.value.weight, require grad: True\n",
            "layer name: encoder.layer.10.attention.self.value.bias, require grad: True\n",
            "layer name: encoder.layer.10.attention.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.10.attention.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.10.attention.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.10.attention.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.10.intermediate.dense.weight, require grad: True\n",
            "layer name: encoder.layer.10.intermediate.dense.bias, require grad: True\n",
            "layer name: encoder.layer.10.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.10.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.10.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.10.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.11.attention.self.query.weight, require grad: True\n",
            "layer name: encoder.layer.11.attention.self.query.bias, require grad: True\n",
            "layer name: encoder.layer.11.attention.self.key.weight, require grad: True\n",
            "layer name: encoder.layer.11.attention.self.key.bias, require grad: True\n",
            "layer name: encoder.layer.11.attention.self.value.weight, require grad: True\n",
            "layer name: encoder.layer.11.attention.self.value.bias, require grad: True\n",
            "layer name: encoder.layer.11.attention.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.11.attention.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.11.attention.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.11.attention.output.LayerNorm.bias, require grad: True\n",
            "layer name: encoder.layer.11.intermediate.dense.weight, require grad: True\n",
            "layer name: encoder.layer.11.intermediate.dense.bias, require grad: True\n",
            "layer name: encoder.layer.11.output.dense.weight, require grad: True\n",
            "layer name: encoder.layer.11.output.dense.bias, require grad: True\n",
            "layer name: encoder.layer.11.output.LayerNorm.weight, require grad: True\n",
            "layer name: encoder.layer.11.output.LayerNorm.bias, require grad: True\n",
            "layer name: pooler.dense.weight, require grad: False\n",
            "layer name: pooler.dense.bias, require grad: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUo-BqUcTpFr"
      },
      "source": [
        "# Design architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_nkBH18UAbM"
      },
      "source": [
        "## Define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyCq9b6p227b"
      },
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask, token_type_ids):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      z = self.bert(sent_id, attention_mask=mask, token_type_ids=token_type_ids)\n",
        "      \n",
        "      x = self.fc1(z[1])\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKNrNo1b3FHy"
      },
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZhyI9o_Tumo"
      },
      "source": [
        "## Set optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZtoy3l23Iht"
      },
      "source": [
        "from transformers import AdamW"
      ],
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOFYlawFVEhS"
      },
      "source": [
        "### Choose weight decay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpvntILm3V0q"
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "optimizer_parameters = [\n",
        "    {\n",
        "        \"params\": [\n",
        "            p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
        "        ],\n",
        "        \"weight_decay\": 0.001,\n",
        "    },\n",
        "    {\n",
        "        \"params\": [\n",
        "            p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
        "        ],\n",
        "        \"weight_decay\": 0.0,\n",
        "    },\n",
        "]"
      ],
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HDFsl6DJwwS"
      },
      "source": [
        "optimizer = AdamW(optimizer_parameters, lr=3e-5)"
      ],
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GI3wJfN3koH",
        "outputId": "e73d2ff1-2b31-40ea-b66f-6be8543cd0f3"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_weights = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
        "\n",
        "print(\"Class Weights:\",class_weights)"
      ],
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class Weights: [0.57743559 3.72848948]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w11hW6U7TzFE"
      },
      "source": [
        "## Define loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9DAywHp3rNy"
      },
      "source": [
        "# converting list of class weights to a tensor\n",
        "weights= torch.tensor(class_weights,dtype=torch.float)\n",
        "\n",
        "# push to GPU\n",
        "weights = weights.to(device)\n",
        "\n",
        "# define the loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n"
      ],
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fpnaOKLT6tk"
      },
      "source": [
        "## Train function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMFawuSh39R3"
      },
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('\\t\\t Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, token_type_ids, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask, token_type_ids)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds\n"
      ],
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVhieepSUDHi"
      },
      "source": [
        "## Evaluate function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im2krXFs4DXj"
      },
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\t ++ Evaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('\\t\\t Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask,token_type_ids, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask, token_type_ids)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSzSA3YR4419"
      },
      "source": [
        "from time import time"
      ],
      "execution_count": 281,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6_s2NjA5SGj"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqT9vAfjUIIh"
      },
      "source": [
        "# Train loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esVsWsB_4KcB",
        "outputId": "8366f6b1-534e-45e2-d9f2-09ef5a2c2891"
      },
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# number of training epochs\n",
        "epochs = 3\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('=====> Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    start_time = time()\n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    end_time = time()\n",
        "    print(f\"\\t >> Training time taken: {np.round((end_time - start_time), 2)} seconds\")\n",
        "\n",
        "    #evaluate model\n",
        "\n",
        "    start_time = time()\n",
        "    valid_loss, _ = evaluate()\n",
        "    end_time = time()\n",
        "    print(f\"\\t >> Evaluation time taken: {np.round((end_time - start_time), 2)} seconds\")\n",
        "\n",
        "    \n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\t >> Training Loss: {train_loss:.3f}')\n",
        "    print(f'\\t >> Validation Loss: {valid_loss:.3f}')\n"
      ],
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=====> Epoch 1 / 3\n",
            "\t\t Batch    50  of    122.\n",
            "\t\t Batch   100  of    122.\n",
            "\t >> Training time taken: 7.9 seconds\n",
            "\t ++ Evaluating...\n",
            "\t >> Evaluation time taken: 1.21 seconds\n",
            "\t >> Training Loss: 0.284\n",
            "\t >> Validation Loss: 0.148\n",
            "=====> Epoch 2 / 3\n",
            "\t\t Batch    50  of    122.\n",
            "\t\t Batch   100  of    122.\n",
            "\t >> Training time taken: 7.88 seconds\n",
            "\t ++ Evaluating...\n",
            "\t >> Evaluation time taken: 1.23 seconds\n",
            "\t >> Training Loss: 0.109\n",
            "\t >> Validation Loss: 0.072\n",
            "=====> Epoch 3 / 3\n",
            "\t\t Batch    50  of    122.\n",
            "\t\t Batch   100  of    122.\n",
            "\t >> Training time taken: 7.93 seconds\n",
            "\t ++ Evaluating...\n",
            "\t >> Evaluation time taken: 1.25 seconds\n",
            "\t >> Training Loss: 0.081\n",
            "\t >> Validation Loss: 0.083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZyhjrMLUK9I"
      },
      "source": [
        "# Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrojWdJy6k5p"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "m6grVhzDMnhz",
        "outputId": "2d9e279e-1af7-4d19-dbb0-04b2fd38cb06"
      },
      "source": [
        "plt.plot(train_losses, label=\"train\")\n",
        "plt.plot(valid_losses, label=\"val\")\n",
        "plt.title(\"Loss vs Epoch\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7e5CdkmUOmA"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnY8p4zrMxtq",
        "outputId": "39e0fb7e-d014-477d-c440-0ecd869c2524"
      },
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGwhDqTgOb5m"
      },
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device), test_token_ids.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uALdT6-2OjrH",
        "outputId": "3647a3f1-de79-433b-ea75-2e4d8dc4af20"
      },
      "source": [
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       724\n",
            "           1       0.92      0.95      0.93       112\n",
            "\n",
            "    accuracy                           0.98       836\n",
            "   macro avg       0.96      0.97      0.96       836\n",
            "weighted avg       0.98      0.98      0.98       836\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccA3Sc5rUVXt"
      },
      "source": [
        "- Surprisingly the **second** finetuning approach (partial freezing of original architecture)has beaten the **third** approach (total freezing of entire network) as seen in the original blog, from where we have taken this example. Here is the reslt from the [blog site](https://www.analyticsvidhya.com/blog/2020/07/transfer-learning-for-nlp-fine-tuning-bert-for-text-classification/)\n",
        "\n",
        "![image](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/07/bert_performance.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpZYaBvwO6cq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}